{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Lambda, merge\n",
    "from keras.layers import Conv2D\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import gym\n",
    "import gym_ple\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree(object):\n",
    "    data_pointer = 0\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity  # for all priority values\n",
    "        self.tree = np.zeros(2 * capacity - 1)\n",
    "        self.data = np.zeros(capacity, dtype=object)\n",
    "\n",
    "    def add(self, p, data):\n",
    "        tree_idx = self.data_pointer + self.capacity - 1\n",
    "        self.data[self.data_pointer] = data  # update data_frame\n",
    "        self.update(tree_idx, p)  # update tree_frame\n",
    "        \n",
    "        self.data_pointer += 1\n",
    "        if self.data_pointer >= self.capacity:  # replace when exceed the capacity\n",
    "            self.data_pointer = 0\n",
    "\n",
    "    def update(self, tree_idx, p):\n",
    "        change = p - self.tree[tree_idx]\n",
    "        self.tree[tree_idx] = p\n",
    "        # then propagate the change through tree\n",
    "        while tree_idx != 0:    # this method is faster than the recursive loop in the reference code\n",
    "            tree_idx = (tree_idx - 1) // 2\n",
    "            self.tree[tree_idx] += change\n",
    "\n",
    "    def get_leaf(self, v):\n",
    "        parent_idx = 0\n",
    "        while True:     # the while loop is faster than the method in the reference code\n",
    "            cl_idx = 2 * parent_idx + 1         # this leaf's left and right kids\n",
    "            cr_idx = cl_idx + 1\n",
    "            if cl_idx >= len(self.tree):        # reach bottom, end search\n",
    "                leaf_idx = parent_idx\n",
    "                break\n",
    "            else:       # downward search, always search for a higher priority node\n",
    "                if v <= self.tree[cl_idx]:\n",
    "                    parent_idx = cl_idx\n",
    "                else:\n",
    "                    v -= self.tree[cl_idx]\n",
    "                    parent_idx = cr_idx\n",
    "\n",
    "        data_idx = leaf_idx - self.capacity + 1\n",
    "        return leaf_idx, self.tree[leaf_idx], self.data[data_idx]\n",
    "    @property\n",
    "    def total_p(self):\n",
    "        return self.tree[0]  # the root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):  # stored as ( s, a, r, s_ ) in SumTree\n",
    "    epsilon = 0.01  # small amount to avoid zero priority\n",
    "    alpha = 0.6  # [0~1] convert the importance of TD error to priority\n",
    "    beta = 0.4  # importance-sampling, from initial value increasing to 1\n",
    "    beta_increment_per_sampling = 0.001\n",
    "    abs_err_upper = 1.  # clipped abs error\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.tree = SumTree(capacity)\n",
    "        self.size = 0\n",
    "    \n",
    "    def store(self, transition):\n",
    "        max_p = np.max(self.tree.tree[-self.tree.capacity:])\n",
    "        if max_p == 0:\n",
    "            max_p = self.abs_err_upper\n",
    "        self.tree.add(max_p, transition)   # set the max p for new p\n",
    "        if self.size < self.tree.capacity:\n",
    "            self.size += 1\n",
    "        \n",
    "    def sample(self, n):\n",
    "        b_idx, b_memory, ISWeights = np.empty((n,), dtype=np.int32), [None] * n, np.empty(n)\n",
    "        pri_seg = self.tree.total_p / n       # priority segment\n",
    "        self.beta = np.min([1., self.beta + self.beta_increment_per_sampling])  # max = 1\n",
    "\n",
    "        max_prob = np.max(self.tree.tree[-self.tree.capacity:]) / self.tree.total_p     # for later calculate ISweight\n",
    "        for i in range(n):\n",
    "            a, b = pri_seg * i, pri_seg * (i + 1)\n",
    "            v = np.random.uniform(a, b)\n",
    "            idx, p, data = self.tree.get_leaf(v)\n",
    "            prob = p / self.tree.total_p\n",
    "            ISWeights[i] = np.power(prob/max_prob, -self.beta)\n",
    "            b_idx[i], b_memory[i] = idx, data\n",
    "        return b_idx, b_memory, ISWeights\n",
    "\n",
    "    def batch_update(self, tree_idx, abs_errors):\n",
    "        abs_errors += self.epsilon  # convert to abs and avoid 0\n",
    "        clipped_errors = np.minimum(abs_errors, self.abs_err_upper)\n",
    "        ps = np.power(clipped_errors, self.alpha)\n",
    "        for ti, p in zip(tree_idx, ps):\n",
    "            self.tree.update(ti, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows , img_cols = 80, 80\n",
    "img_channels = 4 #We stack 4 frames\n",
    "from collections import deque\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.action_size = 2\n",
    "\n",
    "        # These are hyper parameters for the DQN\n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.00025\n",
    "        self.epsilon = 0.15\n",
    "        self.epsilon_min = 0.001\n",
    "        self.batch_size = 32\n",
    "        self.train_start = 20000\n",
    "        self.memory = Memory(capacity=500000)\n",
    "        self.model = self.build_model()\n",
    "        self.target_model = self.build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        x = Input(shape=(img_rows,img_cols,img_channels))\n",
    "        shared = Conv2D(32, (8, 8), strides=(4, 4), activation='relu',kernel_initializer=initializers.random_normal(stddev=0.01))(x)\n",
    "        shared = Conv2D(64, (4, 4), strides=(2, 2), activation='relu',kernel_initializer=initializers.random_normal(stddev=0.01))(shared)\n",
    "        shared = Conv2D(64, (3, 3), strides=(1, 1), activation='relu',kernel_initializer=initializers.random_normal(stddev=0.01))(shared)\n",
    "        flatten = Flatten()(shared)\n",
    "        h = Dense(512,activation='relu',kernel_initializer=initializers.random_normal(stddev=0.01))(flatten)\n",
    "        y = Dense(self.action_size + 1)(h)\n",
    "        z = Lambda(lambda a: K.expand_dims(a[:, 0], -1) + a[:, 1:] - K.max(a[:, 1:], keepdims=True),\n",
    "                   output_shape=(self.action_size,))(y)\n",
    "        \n",
    "        model = Model(input=x, output=z)\n",
    "        model.summary()\n",
    "        model.compile(loss='mse', optimizer=optimizers.Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "    # get action from model using epsilon-greedy policy\n",
    "    def get_action(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        else:\n",
    "            state = state.reshape(1, state.shape[0], state.shape[1], state.shape[2])\n",
    "            q_value = self.model.predict(state)\n",
    "            return np.argmax(q_value[0])\n",
    "\n",
    "    # save sample <s,a,r,s'> to the replay memory\n",
    "    def append_sample(self, state, action, reward, next_state, done):\n",
    "        self.memory.store((state, action, reward, next_state, done))\n",
    "\n",
    "    # pick samples randomly from replay memory (with batch_size)\n",
    "    def train_model(self,tree_idx,minibatch,ISWeights):\n",
    "        batch_size = len(minibatch)        \n",
    "        states = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "        next_states = np.zeros((batch_size, img_rows, img_cols, img_channels))\n",
    "        action, reward, done = [], [], []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            states[i] = minibatch[i][0]\n",
    "            action.append(minibatch[i][1])\n",
    "            reward.append(minibatch[i][2])\n",
    "            next_states[i] = minibatch[i][3]\n",
    "            done.append(minibatch[i][4])\n",
    "\n",
    "        q_eval = self.model.predict(states)\n",
    "        q_target = q_eval.copy()\n",
    "        q_next = self.model.predict(next_states)\n",
    "        q_next_prime = self.target_model.predict(next_states)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            if done[i]:\n",
    "                q_target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                a = np.argmax(q_next[i])\n",
    "                q_target[i][action[i]] = reward[i] + self.discount_factor * (\n",
    "                    q_next_prime[i][a])\n",
    "        \n",
    "        abs_errors = np.sum(np.abs(q_target - q_eval), axis=1)\n",
    "        self.memory.batch_update(tree_idx, abs_errors) \n",
    "        self.model.fit(x=states, \n",
    "            y=q_target, \n",
    "            batch_size=batch_size, \n",
    "            epochs=1, \n",
    "            verbose=0,  \n",
    "            sample_weight=ISWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_state(img):\n",
    "    img = cv2.cvtColor(cv2.resize(img, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, x_t = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    state = np.stack((x_t, x_t, x_t, x_t), axis=2)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent = DQNAgent()\n",
    "scores, episodes = [], []\n",
    "action_count = 0\n",
    "ACTIONS = 2\n",
    "EXPLORE = 250000\n",
    "env = gym.make('FlappyBird-v0')\n",
    "EPISODES = 500000\n",
    "np.random.seed(123)\n",
    "num_frames = 0\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    done = False\n",
    "    score = 0\n",
    "    img = env.reset()\n",
    "    state = get_initial_state(img)\n",
    "    \n",
    "    while not done:\n",
    "#         env.render()\n",
    "        action = agent.get_action(state)\n",
    "        next_img, reward, done,_ = env.step(action)\n",
    "        \n",
    "        #process next image\n",
    "        next_img = cv2.cvtColor(cv2.resize(next_img, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "        ret, next_img = cv2.threshold(next_img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        next_img = next_img.reshape(img_rows, img_cols, 1) #80x80x1\n",
    "        next_state = np.append(next_img,state[:, :, :3],axis=2)\n",
    "        \n",
    "        agent.append_sample(state, action, reward, next_state, done)\n",
    "        \n",
    "        if agent.memory.size > agent.train_start:\n",
    "            if agent.epsilon > agent.epsilon_min:\n",
    "                agent.epsilon -= (agent.epsilon - agent.epsilon_min) / EXPLORE\n",
    "            tree_idx, minibatch, ISWeights = agent.memory.sample(agent.batch_size)                       \n",
    "            agent.train_model(tree_idx, minibatch, ISWeights)   \n",
    "            \n",
    "        num_frames += 1    \n",
    "        score += reward\n",
    "        state = next_state\n",
    "        \n",
    "        if num_frames % 2000 == 0:\n",
    "            agent.update_target_model()\n",
    "        \n",
    "        if done:\n",
    "            scores.append(score)\n",
    "            episodes.append(e)\n",
    "            print(\"episode:\", e, \" score:\", score, \" epsilon:\", agent.epsilon, \" num_frame: \",num_frames)\n",
    "\n",
    "    if e % 1000:\n",
    "        agent.model.save('flappy_bird_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
